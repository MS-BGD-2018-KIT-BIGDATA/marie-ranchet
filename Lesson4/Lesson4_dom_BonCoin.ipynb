{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "url=\"https://www.leboncoin.fr/voitures/offres/ile_de_france/?th=1&q=renault%20zoe\"\n",
    "\n",
    "class Annonce:\n",
    "    def __init__(self, idAnnonce, version, annee, kilometrage, prix, telephone, isPro, description):\n",
    "        self.idAnnonce = idAnnonce\n",
    "        self.version = version\n",
    "        self.annee = annee\n",
    "        self.kilometrage = kilometrage\n",
    "        self.prix = prix\n",
    "        self.telephone = telephone\n",
    "        self.isPro = isPro\n",
    "        self.description = description\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'idAnnonce': self.idAnnonce,\n",
    "            'annee': self.annee,\n",
    "            'kilometrage':self.kilometrage, \n",
    "            'prix':self.prix,\n",
    "            'description':self.description\n",
    "        }\n",
    "\n",
    "def dicoFeatures(x):\n",
    "    return {\n",
    "        'a': 1,\n",
    "        'b': 2\n",
    "    }.get(x, 9)\n",
    "    \n",
    "def getSoupFromURL(url, method='get', data={}):\n",
    "\n",
    "    if method == 'get':\n",
    "        res = requests.get(url)\n",
    "    elif method == 'post':\n",
    "        res = requests.post(url, data=data)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    if res.status_code == 200:\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        return soup\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def getDetail(urlItem, cpt):\n",
    "    #print (a2)\n",
    "    annonce = Annonce(0, 0,0,0,0,0,0,0)\n",
    "    if urlItem != None:\n",
    "        soupItem = getSoupFromURL(urlItem)\n",
    "        if soupItem:\n",
    "            b = soupItem.find_all(class_=\"line\")\n",
    "            for b0 in b:\n",
    "                #print (b0)\n",
    "                b1 = b0.find_all(class_=\"property\")\n",
    "                b1Prime = b0.find_all(class_=\"value\")\n",
    "                                                   \n",
    "                #print (\"++++\")\n",
    "                for b2 in b1:\n",
    "                    for  b2Prime in b1Prime:\n",
    "                        annonce.idAnnonce = cpt\n",
    "                        #print ((b2.text).upper())\n",
    "                        if (b2.text).upper() == \"PRIX\":\n",
    "                            annonce.prix = b2Prime.text.strip()\n",
    "                            #print(b2Prime.text)\n",
    "                        if (b2.text).upper() == \"ANNÉE-MODÈLE\":\n",
    "                            annonce.annee = b2Prime.text.strip()\n",
    "                        if (b2.text).upper() == \"KILOMÉTRAGE\":\n",
    "                            annonce.kilometrage = b2Prime.text.strip()\n",
    "                        if (b2.text).upper() == \"DESCRIPTION :\":\n",
    "                            annonce.description = b2Prime.text\n",
    "                        \n",
    "                        #df[b2] = b2Prime                        \n",
    "                        #print (b2Prime.text)\n",
    "                        #df[b2.text]=b2Prime.text\n",
    "                        \n",
    "    return annonce\n",
    "\n",
    "                    \n",
    "def getInfoVoitures(url):\n",
    "    list = []\n",
    "    columns = [\"version\",\"annee\",\"kilometrage\",\"Prix\",\"telephone\",\"isPro\"]\n",
    "\n",
    "    #dummyarray = np.empty((6,6))\n",
    "    #dummyarray[:] = np.nan\n",
    "\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    soup = getSoupFromURL(url)\n",
    "    if soup:\n",
    "        #a = soup.find_all(class_=\"item_infos\")\n",
    "        a = soup.find_all(class_=\"tabsContent\")\n",
    "        for  a0 in a:\n",
    "            a1 = a0.find_all(\"li\")\n",
    "            cpt=0\n",
    "            for a2 in a1:\n",
    "                urlItem = \"http:\" + a2.find (\"a\")[\"href\"]\n",
    "                \n",
    "                #print (\"-------\"+str(cpt))\n",
    "                annonce = getDetail(urlItem, cpt)  \n",
    "                \n",
    "                #print (\":::::\")\n",
    "                #print (annonce.idAnnonce)\n",
    "                #print (\":::::\")\n",
    "                \n",
    "                #print(a2.find(class_=\"item_title\").text)\n",
    "                if a2.find(class_=\"ispro\")!= None:\n",
    "                    #print(a2.find(class_=\"ispro\").text)\n",
    "                    annonce.isPro = a2.find(class_=\"ispro\").text\n",
    "                else:\n",
    "                    #print ('(NonPro)')\n",
    "                    annonce.isPro = \"(NonPro)\"\n",
    "                #print(a2.find(class_=\"item_price\").text)\n",
    "                cpt=cpt+1\n",
    "                #print (annonce.annee)\n",
    "                list.append(annonce)\n",
    "            \n",
    "    else:\n",
    "        0\n",
    "    return list\n",
    "\n",
    "list = getInfoVoitures(url)\n",
    "\n",
    "df = pd.DataFrame.from_records([s.to_dict() for s in list])\n",
    "df.to_csv(r'pandas.csv', header=None, index=None, sep=',', mode='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
